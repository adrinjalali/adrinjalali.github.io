Title: How we form beliefs, and implications on our beliefs regarding #metoo
Date: 2020-01-15
Tags: ethics, machine-learning
Category: ethics

![celestekiss](files/img/202001-celestekidd-neurips.jpg)

This is a repost of what I posted on
[twitter](https://twitter.com/adrinjalali/status/1217434403044876288).

At NeurIPS @celestekidd gave a keynote on how people form their beliefs. It was
amazing, and had two plot twists which made the audience stand and clap at the
end; something you don't see often in academic conferences. Here's a summary,
and I love how it ends.

1/ Humans continuously form beliefs. These beliefs are constantly updated. In a
sense, our beliefs are probabilistic expectations which directly influence what
we're interested in.

Things which cause a very low, or a very high surprise level, are usually not
interesting to us.

For instance, there's a low chance that I'd enjoy a book teaching the English
alphabet, or a book in a language I don't understand, and is in an alphabet I
don't know, and a topic I'm not familiar with. In theory I could learn all
those things at the same time, but most probably not.

2/ Certainty diminishes interest: you're not curious about things you think you
know. Which makes sense and is reasonable; the issue is when people are certain
about certain issues when they shouldn't be. Anybody who's discussed politics
with extended family is familiar with this

Research shows it's what we think we know defines what we're interested in, and
not what we actually know. Worse: we're more inclined to reject a correct
feedback if we think we already know the [wrong] answer. but why do we have
those wrong beliefs?

3/ Certainty is driven by feedback. At least when it comes to high level
beliefs such as concepts. If there's no feedback to correct people's beliefs,
they may form one w/o proper evidence. If a belief results in correct answers
even if it's not justified, it's reinforced.

This means: if we have a belief, and we look for material online and the first
video we see agrees with that belief, it's reinforced, and that will make us be
interested in material which agree with what we now believe in, even if that
first video was factually wrong.

4/ Less feedback may encourage overconfidence.

People have different ideas of the same concept, let it be "Joe Biden" or "a
cup", even in the same context.

Also, people tend to over estimate how many other people share their
understanding of the same concept.

5/ Humans form beliefs quickly.

Early evidence matters more than later evidence.

For instance, when it comes to "activated charcoal", people go from "unsure" to
"certain it has health benefits" in two or three clicks and a few very short
videos.

Now we get to the interesting conclusions:

There's no such thing as a neutral tech platform: not Facebook, not Google, not
anyone else. Any platform showing content to users, sorts and filters content
for them resulting in forming different beliefs in different people.

Optimizing for engagement on these platforms means we're trying to keep users
on a given platform for longer, and that's through showing them what they
enjoy, which means enforcing what people already believe in and are interested
in, rather than changing or correcting them.

All of that is to say algorithms pushing content online have profound impact on
what we believe, which result in us making decisions, and not benign ones. With
a few clicks we may walk away being convinced that we shouldn't vaccinate our
kid, or that climate change is not real.

The best part: it may seem to be a scary time to be a man in tech right now.
Many men have anxiety about how to talk about gender, and how to interact with
women post #metoo. There's a sense that careers may be destroyed over awkward
passes or misunderstandings.

People do believe that men are being fired for subtle comments or minor jokes.
And this perception rightfully makes people nervous.

The issue is that this perception is not correct, and understanding how we form
beliefs, this is why:

The truth is that it takes an immense amount of mistreatment for most women to
actually complain, due to the fact that most complaints result in retaliation
and law suits cost so much money and time that most people cannot afford.

This prior should tell us that if we hear about a case, some unusually bad
behavior has happened. But why do we believe a minor misconduct?

when a harassment case becomes public, offenders almost universally apologize
for a minor fraction of the offense.

This makes people believe that they're often being prosecuted for a minor
mistreatment, and makes those reportings seem unreasonable or even unethical.

This is unfair to men who are anxious and women who miss out on those
professional interactions.

And finally, 3 takes:

1/ if you hear about a woman complaining around you, she's probably been
through much more than you're aware of.

if you hear about a woman having issues, chances are they're having more issues
and that's the time to ask questions and help them.


2/ when you hear a man apologizing for a misunderstanding, you should know it's
a standard response and completely predictable, no matter what happened from
sexual harassment to sexual assault, and that they're not apologizing for all
their misconducts.

3/ unless men are deeply doing wrong by women around them, they're with very
rare exceptions, incredibly safe.

They shouldn't fear being attacked for minor comments or misunderstandings,
cause that's not what's happening.

It's [false] myth propagated by harassers and offenders.

Here's the link for the full video: [![Celeste Kidd - NeurIPS 2019 - How to
Know](http://img.youtube.com/vi/6qIodcz8o-Q/0.jpg)](https://www.youtube.com/watch?v=6qIodcz8o-Q)
